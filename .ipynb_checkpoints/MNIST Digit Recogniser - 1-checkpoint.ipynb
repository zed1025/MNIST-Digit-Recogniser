{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; color: #0000FF\">MNIST Digit Recognizer</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dataset Link 1](https://www.kaggle.com/c/digit-recognizer/data)\n",
    "\n",
    "[Dataset Link 2](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
    "\n",
    "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\n",
    "\n",
    "```\n",
    "    000 001 002 003 ... 026 027\n",
    "    028 029 030 031 ... 054 055\n",
    "    056 057 058 059 ... 082 083\n",
    "     |   |   |   |  ...  |   |\n",
    "    728 729 730 731 ... 754 755\n",
    "    756 757 758 759 ... 782 783 \n",
    "```\n",
    "\n",
    "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
    "\n",
    "Your submission file should be in the following format: For each of the 28000 images in the test set, output a single line containing the ImageId and the digit you predict. For example, if you predict that the first image is of a 3, the second image is of a 7, and the third image is of a 8, then your submission file would look like:\n",
    "\n",
    "```\n",
    "    ImageId,Label\n",
    "    1,3\n",
    "    2,7\n",
    "    3,8 \n",
    "    (27997 more lines)\n",
    "```\n",
    "\n",
    "The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using pandas to read dataset\n",
    "train_data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    4\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_data['label']\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the lebel column from the dataset\n",
    "train_labels = train_data['label'].values.reshape(42000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have extracted the label column, we remove it from the dataset\n",
    "del train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I've\n",
    "\n",
    "- I've read data from dataset using pandas\n",
    "- removed the label column from the dataset\n",
    "\n",
    "Now I need to figure out a way to convert the pandas.DataFrame and pandas.Series to numpy array. But before that I'll try to write a routine to display the images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_data.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.values.html#pandas.DataFrame.values\n",
    "image = image.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1230d6780>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(index):\n",
    "    image = train_data.iloc[[index]]\n",
    "    image = image.values #convertind the pands.Dataframe to numpy ndarray\n",
    "    plt.imshow(image.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the pandas dataframe to numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Dataset: \n",
      "(42000, 784)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "For the labels: \n",
      "(42000, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('For the Dataset: ')\n",
    "print(train_data.shape)\n",
    "print(type(train_data))\n",
    "\n",
    "print('\\nFor the labels: ')\n",
    "print(train_labels.shape)\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we need to convert the train_data to numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.values\n",
    "print(train_data.shape)\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will load the test set later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Layer NN for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: initialize_parameters(n_x, n_h, n_y)\n",
    "Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "        W1 -- weight matrix of shape (n_h, n_x)\n",
    "        b1 -- bias vector of shape (n_h, 1)\n",
    "        W2 -- weight matrix of shape (n_y, n_h)\n",
    "        b2 -- bias vector of shape (n_y, 1)\n",
    "'''\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function: linear_forward(A, W, b)\n",
    "Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "Arguments:\n",
    "A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "Returns:\n",
    "Z -- the input of the activation function, also called pre-activation parameter \n",
    "cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "\"\"\"\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W, A) + b\n",
    "    \n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: linear_activation_forward(A_prev, W, b, activation)\n",
    "Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "Arguments:\n",
    "A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "Returns:\n",
    "A -- the output of the activation function, also called the post-activation value \n",
    "cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "         stored for computing the backward pass efficiently\n",
    "'''\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function: compute_cost(Al, Y)\n",
    "Implement the cost function defined by equation (7).\n",
    "\n",
    "Arguments:\n",
    "AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "Returns:\n",
    "cost -- cross-entropy cost\n",
    "\"\"\"\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = - (np.sum(np.dot(Y, np.log(AL).T) + np.dot((1-Y), np.log(1-AL).T))) / m\n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function: linear_activation_backward(dA, cache, activation)\n",
    "Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "\n",
    "Arguments:\n",
    "dA -- post-activation gradient for current layer l \n",
    "cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "Returns:\n",
    "dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "\"\"\"\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://stackoverflow.com/questions/42240376/dataframe-object-has-no-attribute-reshape\n",
    "- https://stackoverflow.com/questions/38308378/tensorflow-show-image-from-mnist-dataset\n",
    "- https://stackoverflow.com/questions/46317216/numpy-ndarray-object-is-not-callable-using-pandas\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
